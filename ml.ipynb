{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import utils as u\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load in data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./data/data.db\"):\n",
    "    os.system(\"python build_db.py\")\n",
    "\n",
    "conn = sqlite3.connect(\"./data/data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "\n",
    "COLS_EXCLUDE = set([\n",
    "    \"StateAbbr\",\n",
    "    \"StateDesc\",\n",
    "    \"CountyName\",\n",
    "    \"CountyFIPS\",\n",
    "    \"TractFIPS\",\n",
    "    \"fips\",\n",
    "    \"stateabb\",\n",
    "    \"sedaadmin\",\n",
    "    \"sedaadminname\",\n",
    "    \"TRACT\",\n",
    "    \"COUNT\"\n",
    "])\n",
    "\n",
    "if not os.path.exists(\"./data/full_joined_table.csv\"):\n",
    "    c.execute(f\"\"\"\n",
    "    WITH seda_tracts AS (\n",
    "        SELECT *\n",
    "        FROM seda s\n",
    "        JOIN nces n\n",
    "        ON s.sedaadmin = n.LEAID\n",
    "        WHERE s.year = 2019\n",
    "    )\n",
    "\n",
    "    , food_atlas_tracts AS (\n",
    "        SELECT *\n",
    "        FROM food f\n",
    "        JOIN seda_tracts st\n",
    "        ON st.TRACT = f.CensusTract\n",
    "    )\n",
    "\n",
    "    , cdc_tracts AS (\n",
    "        SELECT *\n",
    "        FROM cdc c\n",
    "        JOIN food_atlas_tracts ft\n",
    "        ON ft.TRACT = c.TractFIPS\n",
    "    )\n",
    "\n",
    "    SELECT *\n",
    "    FROM cdc_tracts;\n",
    "    \"\"\")\n",
    "\n",
    "    rows = c.fetchall()\n",
    "    print(len(rows))\n",
    "    columns = [col[0] for col in c.description]\n",
    "\n",
    "    ## Write the rows manually into a CSV file without pandas\n",
    "    to_remove = [\n",
    "        \"StateAbbr\",\n",
    "        \"CountyName\",\n",
    "        \"TractFIPS\",\n",
    "        \"stateabb\",\n",
    "        \"MHLTH_CrudePrev:1\",\n",
    "        \"SLEEP_CrudePrev:1\",\n",
    "        \"fips\",\n",
    "        \"LEAID\",\n",
    "        \"NAME_LEA19\",\n",
    "        \"TRACT\",\n",
    "        \"COUNT\"\n",
    "    ]\n",
    "    to_remove_idx = set([i for i, col in enumerate(columns) if col in to_remove])\n",
    "    with open(\"data/full_joined_table.csv\", \"w\") as f:\n",
    "        race_cols = []\n",
    "        f.write(\",\".join([col for i, col in enumerate(columns) if i not in to_remove_idx]) + \"\\n\")\n",
    "        for row in tqdm(rows):\n",
    "            # if row[0] == \"CA\":\n",
    "            f.write(\",\".join([str(x) for i, x in enumerate(row) if i not in to_remove_idx]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/full_joined_table.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gcs_mn_all.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gcs_mn_se_all.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_cols = [\n",
    "    \"CensusTract\",\n",
    "    \"State\",\n",
    "    \"County\",\n",
    "    \"sedaadmin\",\n",
    "    \"sedaadminname\",\n",
    "    \"subject\",\n",
    "    \"grade\"\n",
    "]\n",
    "\n",
    "health_feature_cols = [\n",
    "    \"MHLTH_CrudePrev\", # cont\n",
    "    \"SLEEP_CrudePrev\", # cont\n",
    "]\n",
    "\n",
    "food_desert_cols = [\n",
    "    \"Urban\",            # bool\n",
    "    \"LATracts_half\",    # bool\n",
    "    \"LATracts10\",       # bool\n",
    "    \"PovertyRate\",      # cont\n",
    "    \"LowIncomeTracts\",  # bool\n",
    "    \"lahunvhalfshare\",  # bool\n",
    "    \"lahunv10share\",    # bool\n",
    "]\n",
    "\n",
    "academics_all_cols = [\n",
    "    \"gcs_mn_all\", \"gcs_mn_se_all\", \"tot_asmt_all\",\n",
    "    \"gcs_mn_asn\", \"gcs_mn_se_asn\", \"tot_asmt_asn\",\n",
    "    \"gcs_mn_blk\", \"gcs_mn_se_blk\", \"tot_asmt_blk\",\n",
    "    \"gcs_mn_ecd\", \"gcs_mn_se_ecd\", \"tot_asmt_ecd\",\n",
    "    \"gcs_mn_fem\", \"gcs_mn_se_fem\", \"tot_asmt_fem\",\n",
    "    \"gcs_mn_hsp\", \"gcs_mn_se_hsp\", \"tot_asmt_hsp\",\n",
    "    \"gcs_mn_mal\", \"gcs_mn_se_mal\", \"tot_asmt_mal\",\n",
    "    \"gcs_mn_mfg\", \"gcs_mn_se_mfg\", \"tot_asmt_mfg\",\n",
    "    \"gcs_mn_nam\", \"gcs_mn_se_nam\", \"tot_asmt_nam\",\n",
    "    \"gcs_mn_nec\", \"gcs_mn_se_nec\", \"tot_asmt_nec\",\n",
    "    \"gcs_mn_neg\", \"gcs_mn_se_neg\", \"tot_asmt_neg\",\n",
    "    \"gcs_mn_wag\", \"gcs_mn_se_wag\", \"tot_asmt_wag\",\n",
    "    \"gcs_mn_wbg\", \"gcs_mn_se_wbg\", \"tot_asmt_wbg\",\n",
    "    \"gcs_mn_whg\", \"gcs_mn_se_whg\", \"tot_asmt_whg\",\n",
    "    \"gcs_mn_wht\", \"gcs_mn_se_wht\", \"tot_asmt_wht\",\n",
    "    \"gcs_mn_wng\", \"gcs_mn_se_wng\", \"tot_asmt_wng\",\n",
    "]\n",
    "\n",
    "academics_race_cols = [\n",
    "    \"gcs_mn_all\", \"gcs_mn_se_all\", \"tot_asmt_all\",\n",
    "    \"gcs_mn_wht\", \"gcs_mn_se_wht\", \"tot_asmt_wht\",\n",
    "    \"gcs_mn_asn\", \"gcs_mn_se_asn\", \"tot_asmt_asn\",\n",
    "    \"gcs_mn_blk\", \"gcs_mn_se_blk\", \"tot_asmt_blk\",\n",
    "    \"gcs_mn_hsp\", \"gcs_mn_se_hsp\", \"tot_asmt_hsp\",\n",
    "    \"gcs_mn_nam\", \"gcs_mn_se_nam\", \"tot_asmt_nam\",\n",
    "]\n",
    "\n",
    "academics_gender_cols = [\n",
    "    # \"gcs_mn_all\", \"gcs_mn_se_all\", \"tot_asmt_all\",\n",
    "    \"gcs_mn_fem\", \"gcs_mn_se_fem\", \"tot_asmt_fem\",\n",
    "    \"gcs_mn_mal\", \"gcs_mn_se_mal\", \"tot_asmt_mal\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification/clustering by race**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude lahunv10share since it is mostly NaN\n",
    "feature_cols = academics_all_cols + health_feature_cols\n",
    "race_df = df[academics_all_cols + health_feature_cols + food_desert_cols[:-1] + meta_data_cols].copy()\n",
    "print(f\"Original length: {len(race_df)}\")\n",
    "race_df = race_df.dropna().reset_index(drop=True)\n",
    "race_df[\"y\"] = race_df.apply(lambda row: str(row[\"Urban\"]) + str(row[\"LATracts_half\"]), axis=1)\n",
    "print(f\"Length after dropping NaNs: {len(race_df)}\")\n",
    "race_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_map = race_df[feature_cols].corr()\n",
    "plt.figure(figsize=(28, 24))\n",
    "sns.heatmap(corr_map, annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrelated_features, correlated_features = u.de_correlate(race_df[feature_cols])\n",
    "corr_map = race_df[uncorrelated_features].corr()\n",
    "plt.figure(figsize=(24, 18))\n",
    "sns.heatmap(corr_map, annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Removed: {correlated_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df_no_corr_mth = race_df[race_df.subject == \"mth\"].drop(correlated_features, axis=1)\n",
    "race_df_no_corr_rla = race_df[race_df.subject == \"rla\"].drop(correlated_features, axis=1)\n",
    "print(f\"Math df length: {len(race_df_no_corr_mth)}\")\n",
    "print(f\"Reading/Language Arts df length: {len(race_df_no_corr_rla)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.03, 0.01],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "param_combinations = list(product(\n",
    "    param_grid[\"learning_rate\"],\n",
    "    param_grid[\"n_estimators\"],\n",
    "    param_grid[\"max_depth\"]\n",
    "))\n",
    "\n",
    "datasets = [(\"Math\", race_df_no_corr_mth), (\"RLA\", race_df_no_corr_rla)]\n",
    "best_params = {\n",
    "    \"Math\": {},\n",
    "    \"RLA\": {}\n",
    "}\n",
    "for dataset in datasets:\n",
    "    name, df = dataset\n",
    "    print(f\"Dataset: {name}\")\n",
    "\n",
    "    X = df[uncorrelated_features]\n",
    "\n",
    "    one_hot = OneHotEncoder(sparse_output=False)\n",
    "    one_hot.fit(df.y.values.reshape(-1, 1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, df.y, test_size=0.2, random_state=42)\n",
    "    label_counts = y_test.value_counts()\n",
    "    print(f\"Baseline accuracy: {label_counts.max() / label_counts.sum():.4f}\")\n",
    "\n",
    "    param_results = {}\n",
    "    for lr, n_estimators, max_depth in param_combinations:\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_cv_train, X_cv_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            y_cv_train = one_hot.transform(y_cv_train.values.reshape(-1, 1))\n",
    "            y_cv_val = one_hot.transform(y_cv_val.values.reshape(-1, 1))\n",
    "            y_cv_train = y_cv_train.argmax(axis=1)\n",
    "            y_cv_val = y_cv_val.argmax(axis=1)\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_cv_train = scaler.fit_transform(X_cv_train.values)\n",
    "            X_cv_val = scaler.transform(X_cv_val.values)\n",
    "\n",
    "            model = xgb.XGBClassifier(\n",
    "                objective=\"multi:softmax\",\n",
    "                num_class=3,\n",
    "                learning_rate=lr,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            weights = compute_sample_weight(class_weight=\"balanced\", y=y_cv_train)\n",
    "            model.fit(X_cv_train, y_cv_train, verbose=False, sample_weight=weights)\n",
    "            cv_scores.append(model.score(X_cv_val, y_cv_val))\n",
    "\n",
    "        print(f\"[{lr}|{n_estimators}|{max_depth}] Val accuracy: {np.mean(cv_scores):.4f} +/- {np.std(cv_scores):.4f}\")\n",
    "        param_results[(lr, n_estimators, max_depth)] = np.mean(cv_scores)\n",
    "\n",
    "    best_params[name] = max(param_results, key=param_results.get)\n",
    "\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1951a_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
